외국인 채용 데이터 파이프라인 구축 (MVP) 요청의 건

지난 1월을 회고해보니, 얼마나 타겟들에게 ‘유익한’ 컨텐츠를 찍는게 어려운지 (기획부터 실행까지의 에너지 소모) 깨닫게 되었고, 개인의 큐레이션이라는 것도 얼마나 촌스러운 것인지 새삼 느낍니다. 그래도 비자와, 채용 절차에 대한 공부를 할 수 있었고, 컨텐츠를 다시 찍을 수 있도록 sns 를 셋팅하고 올렸다는 것에 의의를 둡니다. 
2월에는 좀 더 ‘효율적인 일하는 구조’를 만드는데 초점을 맞춰서 다음 세 가지 일을 해보려고 합니다. 
‘유익함’을 기술적으로 만들기: 주요 채용 사이트의 채용 정보를 ‘중복 없이’ ‘필터링’ 하여 보여주는 검색 사이트 제작
‘유익함’을 활용하여 콘텐츠 만들기: 위클리 채용 리포트 발간, 분석, 콘텐츠 발행
‘유익한 정보’로 해결할 수 없는 ‘실력’ 팔기: 한국어 이력서 첨삭, 한국어 면접 코칭, 속성 비즈니스 한국어 배우기 

이 첫번째 과정에서 필요한 것이 '통합 채용 검색 엔진' 입니다. 직접 노코드 툴(Browse AI)로 프로토타입을 돌려봤는데, 스크랩핑  기능이 잘 된다는 것은 확인했으나 크레딧이 너무 비싸서 오빠의 도움이 필요한 상황입니다. 
1. 요청 사항 (Scope)
3개 채용 사이트에서 데이터를 긁어서 내가 만든 구글 스프레드시트에 자동으로 쌓아주는 파이프라인 구축
2. 기술 사양 (Spec)
Target: 코워크(KOWORK), 코메이트(komate), 클릭(Klik)
Method: 1. 리스트 페이지에서 공고를 긁는다. 2. 각 공고의 상세 URL을 타고 들어가서 상세 본문(JD) 전체를 가져온다 (Deep Scraping).
Output: 구글 시트(API 연동)에 행(Row) 단위로 데이터 추가
3. 데이터 스키마 (이후 수정 가능)
시트에 아래 컬럼(Column) 순서대로 넣어주면 됩니다. 스크랩핑 당시 주요 언어는 ‘영어’로 통일하여 작업합니다. 
URL: 공고 고유 주소 (중복 체크용 ID)
Title: 공고 제목
Company(kor): 한국 회사명(kowork, komate 영문페이지에서도 한글 회사명 제공, 단 klik은 링크로 연결된 별도의 웹사이트에서 제공)
Company(eng): 영문 회사명( 사이트 간 중복 확인을 할 때 필수)
Location: 근무지 (도시 레벨까지만 수집, 3개의 웹사이트 모두 제공)
Visa: 지원 가능한 비자 타입
E-7 Visa Support: E-7 비자 지원 필터링은 별도로 스크랩
Korean_Requirement: 본문 내 한국어 요구사항 관련 키워드 (TOPIK 등), 각 웹 사이트 마다 프론트 페이지에서 수집 가능한 경우, 스크롤 다운해야 볼 수 있는 경우가 다름 ** 가장 중요**
Job category: 직무, komate에서는 duties라고도 표기됨, KLik  에서는 직무 정보가 필터링 정보로 제공되고 있지 않아, 상세 정보에서 추출해야할 것으로 예상됨.
Job type: komate, KLik 에서는 job working condition이라고 표기됨
Content_Raw: 상세 본문 전체 텍스트 (qualifications, preferred, cover letter 필요 여부 등)